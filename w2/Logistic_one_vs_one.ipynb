{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_one_vs_one.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMIII-IQfCyZ"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "\r\n",
        "def raw_data():\r\n",
        "  data = pd.read_csv('/content/iris.data',names=['Sepal Length', 'Sepal Width', 'Petal Length', 'Petal Width', 'iris_class'])\r\n",
        "  data[\"iris_class\"].replace({\"Iris-setosa\": 0., \"Iris-virginica\": 1., \"Iris-versicolor\": 2.}, inplace=True)\r\n",
        "  data1 = data[data.iris_class != 2] # 0 and 1\r\n",
        "  data2 = data[data.iris_class != 1] # 0 and 2\r\n",
        "  data3 = data[data.iris_class != 0] # 1 and 2\r\n",
        "  return data1, data2, data3\r\n",
        "\r\n",
        "def prepared_data():\r\n",
        "  data1, data2, data3 = raw_data()\r\n",
        "  data2[\"iris_class\"].replace({2:1}, inplace=True)\r\n",
        "  data3[\"iris_class\"].replace({1:0, 2:1}, inplace=True)\r\n",
        "  X_train1, X_test1, y_train1, y_test1 = train_test_split(data1.iloc[ : , 0:-1], data1.iloc[ : , -1], \r\n",
        "                                                        stratify=data1['iris_class'], test_size=0.2, random_state=2020)\r\n",
        "  X_train2, X_test2, y_train2, y_test2 = train_test_split(data2.iloc[ : , 0:-1], data2.iloc[ : , -1],\r\n",
        "                                                        stratify=data2['iris_class'], test_size=0.2, random_state=2020)\r\n",
        "  X_train3, X_test3, y_train3, y_test3 = train_test_split(data3.iloc[ : , 0:-1], data3.iloc[ : , -1],\r\n",
        "                                                      stratify=data3['iris_class'], test_size=0.2, random_state=2020)\r\n",
        "  \r\n",
        "  X_train1, X_test1 = addbias(X_train1), addbias(X_test1)\r\n",
        "  X_train2, X_test2 = addbias(X_train2), addbias(X_test2)\r\n",
        "  X_train3, X_test3 = addbias(X_train3), addbias(X_test3)\r\n",
        "  res1 = (X_train1, X_test1, y_train1.to_numpy(), y_test1.to_numpy())\r\n",
        "  res2 = (X_train2, X_test2, y_train2.to_numpy(), y_test2.to_numpy())\r\n",
        "  res3 = (X_train3, X_test3, y_train3.to_numpy(), y_test3.to_numpy())\r\n",
        "  return res1, res2, res3\r\n",
        "\r\n",
        "def init_weights(shape):\r\n",
        "  return np.zeros(shape, dtype='float64')\r\n",
        "\r\n",
        "def relabel_data(y):\r\n",
        "    label = list(set(y))\r\n",
        "    relabeled_data = np.zeros(len(y)*len(label)).reshape(len(y),len(label))\r\n",
        "    for i in range(len(label)):\r\n",
        "        relabeled_data[y==label[i],i] = 1\r\n",
        "    return relabeled_data\r\n",
        "\r\n",
        "def addbias(x):\r\n",
        "    return np.concatenate((np.ones((len(x))).reshape(-1,1), x),axis = 1)\r\n",
        "\r\n",
        "def sigmoid(x):\r\n",
        "    return 1 / (1 + np.exp(-x))\r\n",
        "\r\n",
        "def compute_loss(y_, y):\r\n",
        "  return -1/y.size * np.sum(y * np.log(y_) + (1 - y) * np.log(1 - y_), axis=0)\r\n",
        "\r\n",
        "def gradient_dsc(X, y, y_):\r\n",
        "  return np.dot(X.T, (y_ - y)) / y.size\r\n",
        "\r\n",
        "def update_weights(w, lr, grad):\r\n",
        "  return w - lr * grad.T\r\n",
        "\r\n",
        "def mse(y_, y):\r\n",
        "  diff = np.subtract(y_, y)\r\n",
        "  ms = np.power(diff, 2, dtype='float64')\r\n",
        "  return np.mean(ms)\r\n",
        "\r\n",
        "def train(X_train, y_train, lr, epochs, weights): \r\n",
        "    for i in range(epochs): \r\n",
        "        xw = np.dot(X_train, weights.T)\r\n",
        "        prob = sigmoid(xw)\r\n",
        "        grad = gradient_dsc(X_train, y_train, prob)\r\n",
        "        weights = update_weights(weights, lr, grad)\r\n",
        "        loss = compute_loss(prob, y_train)\r\n",
        "        loss_log.append(loss)\r\n",
        "    return weights\r\n",
        "\r\n",
        "def predict(X, weights):\r\n",
        "    z = np.dot(X, weights.T)\r\n",
        "    return sigmoid(z)\r\n",
        "\r\n",
        "def predict_label(X, weights):\r\n",
        "  labels = []\r\n",
        "  for i in range(len(X)):\r\n",
        "    temp = [0, 0, 0]\r\n",
        "    l1 = 1 if predict(X[i], weights[0]) >= 0.5 else 0\r\n",
        "    l2 = 1 if predict(X[i], weights[1]) >= 0.5 else 0\r\n",
        "    l3 = 1 if predict(X[i], weights[2]) >= 0.5 else 0\r\n",
        "    if l1 == 1:\r\n",
        "      temp[1] = temp[1] + 1\r\n",
        "    else:\r\n",
        "      temp[0] = temp[0] + 1\r\n",
        "    if l2 == 1:\r\n",
        "      temp[2] = temp[2] + 1\r\n",
        "    else:\r\n",
        "      temp[0] = temp[0] + 1\r\n",
        "    if l3 == 1:\r\n",
        "      temp[2] = temp[2] + 1\r\n",
        "    else:\r\n",
        "      temp[1] = temp[1] + 1\r\n",
        "    labels.append(temp)\r\n",
        "  return [l.index(max(l)) for l in labels]\r\n",
        "\r\n",
        "loss_log = []\r\n",
        "epochs = 20000\r\n",
        "lr = 0.01\r\n",
        "\r\n",
        "dataset1, dataset2, dataset3 = prepared_data()\r\n",
        "num_of_w = dataset1[0].shape[1]\r\n",
        "weights1 = init_weights(num_of_w)\r\n",
        "weights2 = init_weights(num_of_w)\r\n",
        "weights3 = init_weights(num_of_w)\r\n",
        "\r\n",
        "weights01 = train(dataset1[0], dataset1[2], lr, epochs, weights1)\r\n",
        "weights02 = train(dataset2[0], dataset2[2], lr, epochs, weights2)\r\n",
        "weights12 = train(dataset3[0], dataset3[2], lr, epochs, weights3)\r\n",
        "weights = [weights01, weights02, weights12]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II8xM9nc4HyP"
      },
      "source": [
        "def prepare_data_for_acc():\r\n",
        "  data1, data2, data3 = raw_data()\r\n",
        "  X_train1, X_test1, y_train1, y_test1 = train_test_split(data1.iloc[ : , 0:-1], data1.iloc[ : , -1], \r\n",
        "                                                        stratify=data1['iris_class'], test_size=0.2, random_state=2020)\r\n",
        "  X_train2, X_test2, y_train2, y_test2 = train_test_split(data2.iloc[ : , 0:-1], data2.iloc[ : , -1],\r\n",
        "                                                        stratify=data2['iris_class'], test_size=0.2, random_state=2020)\r\n",
        "  X_train3, X_test3, y_train3, y_test3 = train_test_split(data3.iloc[ : , 0:-1], data3.iloc[ : , -1],\r\n",
        "                                                      stratify=data3['iris_class'], test_size=0.2, random_state=2020)\r\n",
        "  \r\n",
        "  X_train1, X_test1 = addbias(X_train1), addbias(X_test1)\r\n",
        "  X_train2, X_test2 = addbias(X_train2), addbias(X_test2)\r\n",
        "  X_train3, X_test3 = addbias(X_train3), addbias(X_test3)\r\n",
        "  res1 = (X_train1, X_test1, y_train1.to_numpy(), y_test1.to_numpy())\r\n",
        "  res2 = (X_train2, X_test2, y_train2.to_numpy(), y_test2.to_numpy())\r\n",
        "  res3 = (X_train3, X_test3, y_train3.to_numpy(), y_test3.to_numpy())\r\n",
        "  return res1, res2, res3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdNHJC_Q2IGC",
        "outputId": "de399201-a7a0-4450-86e8-9673b1db06ad"
      },
      "source": [
        "# report train and test accuracy for both of method\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "dataset1, dataset2, dataset3 = prepare_data_for_acc()\r\n",
        "y_pred = predict_label(dataset2[0], weights)\r\n",
        "y_true = dataset2[2]\r\n",
        "print(\"Train Accuracy : \", accuracy_score(y_true, y_pred))\r\n",
        "\r\n",
        "y_pred = predict_label(dataset2[1], weights)\r\n",
        "y_true = dataset2[3]\r\n",
        "print(\"Test Accuracy : \", accuracy_score(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy :  0.9625\n",
            "Test Accuracy :  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EncD7p5my0Qj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}